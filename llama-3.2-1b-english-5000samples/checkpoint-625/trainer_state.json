{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 1000,
  "global_step": 625,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 0.858863890171051,
      "learning_rate": 0.00019712,
      "loss": 2.413,
      "step": 10
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.7277867197990417,
      "learning_rate": 0.00019392000000000001,
      "loss": 1.9904,
      "step": 20
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.7875937223434448,
      "learning_rate": 0.00019072000000000002,
      "loss": 1.9252,
      "step": 30
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.8911604285240173,
      "learning_rate": 0.00018752,
      "loss": 1.9863,
      "step": 40
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.215340495109558,
      "learning_rate": 0.00018432,
      "loss": 1.9367,
      "step": 50
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.8400995135307312,
      "learning_rate": 0.00018112,
      "loss": 1.9266,
      "step": 60
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.9255020618438721,
      "learning_rate": 0.00017792,
      "loss": 1.9157,
      "step": 70
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.7972080111503601,
      "learning_rate": 0.00017472,
      "loss": 1.771,
      "step": 80
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.734387218952179,
      "learning_rate": 0.00017152,
      "loss": 1.8604,
      "step": 90
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6375232934951782,
      "learning_rate": 0.00016832000000000001,
      "loss": 1.8309,
      "step": 100
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.6727840304374695,
      "learning_rate": 0.00016512000000000002,
      "loss": 1.8503,
      "step": 110
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.7123956084251404,
      "learning_rate": 0.00016192,
      "loss": 1.8523,
      "step": 120
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.9204483032226562,
      "learning_rate": 0.00015872,
      "loss": 1.8001,
      "step": 130
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.7882044911384583,
      "learning_rate": 0.00015552,
      "loss": 1.846,
      "step": 140
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6335604190826416,
      "learning_rate": 0.00015232,
      "loss": 1.8832,
      "step": 150
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.6566185355186462,
      "learning_rate": 0.00014912,
      "loss": 1.8056,
      "step": 160
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.6991564631462097,
      "learning_rate": 0.00014592,
      "loss": 1.8666,
      "step": 170
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.716106116771698,
      "learning_rate": 0.00014272000000000002,
      "loss": 1.8032,
      "step": 180
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.7640456557273865,
      "learning_rate": 0.00013952000000000002,
      "loss": 1.8091,
      "step": 190
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7716646790504456,
      "learning_rate": 0.00013632,
      "loss": 1.8163,
      "step": 200
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.6440467834472656,
      "learning_rate": 0.00013312,
      "loss": 1.8658,
      "step": 210
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.7362627983093262,
      "learning_rate": 0.00012992,
      "loss": 1.8591,
      "step": 220
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.6728795766830444,
      "learning_rate": 0.00012672,
      "loss": 1.7522,
      "step": 230
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.7153632640838623,
      "learning_rate": 0.00012352,
      "loss": 1.8288,
      "step": 240
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.62505704164505,
      "learning_rate": 0.00012032000000000001,
      "loss": 1.7318,
      "step": 250
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.6858049631118774,
      "learning_rate": 0.00011712,
      "loss": 1.8365,
      "step": 260
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.6301480531692505,
      "learning_rate": 0.00011392000000000001,
      "loss": 1.8305,
      "step": 270
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.6098191738128662,
      "learning_rate": 0.00011072,
      "loss": 1.7378,
      "step": 280
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.6727996468544006,
      "learning_rate": 0.00010752,
      "loss": 1.7446,
      "step": 290
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.74285888671875,
      "learning_rate": 0.00010431999999999999,
      "loss": 1.7408,
      "step": 300
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.6773821115493774,
      "learning_rate": 0.00010112000000000002,
      "loss": 1.8133,
      "step": 310
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.6458234190940857,
      "learning_rate": 9.792e-05,
      "loss": 1.8147,
      "step": 320
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.716743528842926,
      "learning_rate": 9.472000000000001e-05,
      "loss": 1.7617,
      "step": 330
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.7347546815872192,
      "learning_rate": 9.152e-05,
      "loss": 1.7995,
      "step": 340
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6319882273674011,
      "learning_rate": 8.832000000000001e-05,
      "loss": 1.7293,
      "step": 350
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.6603368520736694,
      "learning_rate": 8.512e-05,
      "loss": 1.7404,
      "step": 360
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.6689571142196655,
      "learning_rate": 8.192e-05,
      "loss": 1.7928,
      "step": 370
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.7102557420730591,
      "learning_rate": 7.872e-05,
      "loss": 1.798,
      "step": 380
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.6563449501991272,
      "learning_rate": 7.552e-05,
      "loss": 1.7938,
      "step": 390
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6409540772438049,
      "learning_rate": 7.232e-05,
      "loss": 1.7799,
      "step": 400
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.6858848929405212,
      "learning_rate": 6.912e-05,
      "loss": 1.8239,
      "step": 410
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.6286951303482056,
      "learning_rate": 6.592e-05,
      "loss": 1.7867,
      "step": 420
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.6354304552078247,
      "learning_rate": 6.272e-05,
      "loss": 1.7085,
      "step": 430
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.6808525323867798,
      "learning_rate": 5.952e-05,
      "loss": 1.7779,
      "step": 440
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6727508902549744,
      "learning_rate": 5.632e-05,
      "loss": 1.8638,
      "step": 450
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.6443741321563721,
      "learning_rate": 5.3120000000000006e-05,
      "loss": 1.7453,
      "step": 460
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.6789790391921997,
      "learning_rate": 4.992e-05,
      "loss": 1.7822,
      "step": 470
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.6791470646858215,
      "learning_rate": 4.672e-05,
      "loss": 1.8292,
      "step": 480
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.6835030317306519,
      "learning_rate": 4.352e-05,
      "loss": 1.7965,
      "step": 490
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6583389639854431,
      "learning_rate": 4.032e-05,
      "loss": 1.8418,
      "step": 500
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.6860846281051636,
      "learning_rate": 3.712e-05,
      "loss": 1.7814,
      "step": 510
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.6805181503295898,
      "learning_rate": 3.392e-05,
      "loss": 1.7338,
      "step": 520
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.6967978477478027,
      "learning_rate": 3.072e-05,
      "loss": 1.8405,
      "step": 530
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.6749622821807861,
      "learning_rate": 2.752e-05,
      "loss": 1.6821,
      "step": 540
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.658056914806366,
      "learning_rate": 2.432e-05,
      "loss": 1.8727,
      "step": 550
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.777702808380127,
      "learning_rate": 2.112e-05,
      "loss": 1.8222,
      "step": 560
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.6442698836326599,
      "learning_rate": 1.792e-05,
      "loss": 1.8186,
      "step": 570
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.6744014024734497,
      "learning_rate": 1.472e-05,
      "loss": 1.7772,
      "step": 580
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.616615355014801,
      "learning_rate": 1.152e-05,
      "loss": 1.8076,
      "step": 590
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.735482394695282,
      "learning_rate": 8.32e-06,
      "loss": 1.7201,
      "step": 600
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.6522066593170166,
      "learning_rate": 5.12e-06,
      "loss": 1.7818,
      "step": 610
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.6805938482284546,
      "learning_rate": 1.92e-06,
      "loss": 1.7792,
      "step": 620
    }
  ],
  "logging_steps": 10,
  "max_steps": 625,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.048266059776e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
