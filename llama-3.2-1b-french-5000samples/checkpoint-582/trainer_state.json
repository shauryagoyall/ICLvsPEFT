{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 1000,
  "global_step": 582,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01718213058419244,
      "grad_norm": 0.8943058848381042,
      "learning_rate": 0.00019690721649484537,
      "loss": 2.2149,
      "step": 10
    },
    {
      "epoch": 0.03436426116838488,
      "grad_norm": 0.8292160630226135,
      "learning_rate": 0.0001934707903780069,
      "loss": 1.8892,
      "step": 20
    },
    {
      "epoch": 0.05154639175257732,
      "grad_norm": 0.8541183471679688,
      "learning_rate": 0.00019003436426116838,
      "loss": 1.7939,
      "step": 30
    },
    {
      "epoch": 0.06872852233676977,
      "grad_norm": 0.9349741339683533,
      "learning_rate": 0.0001865979381443299,
      "loss": 1.783,
      "step": 40
    },
    {
      "epoch": 0.0859106529209622,
      "grad_norm": 0.8159092664718628,
      "learning_rate": 0.00018316151202749141,
      "loss": 1.8026,
      "step": 50
    },
    {
      "epoch": 0.10309278350515463,
      "grad_norm": 1.3909318447113037,
      "learning_rate": 0.00017972508591065293,
      "loss": 1.7844,
      "step": 60
    },
    {
      "epoch": 0.12027491408934708,
      "grad_norm": 0.9851593375205994,
      "learning_rate": 0.00017628865979381445,
      "loss": 1.6644,
      "step": 70
    },
    {
      "epoch": 0.13745704467353953,
      "grad_norm": 1.0903406143188477,
      "learning_rate": 0.00017285223367697597,
      "loss": 1.6903,
      "step": 80
    },
    {
      "epoch": 0.15463917525773196,
      "grad_norm": 0.7763632535934448,
      "learning_rate": 0.00016941580756013746,
      "loss": 1.6634,
      "step": 90
    },
    {
      "epoch": 0.1718213058419244,
      "grad_norm": 0.7178690433502197,
      "learning_rate": 0.00016597938144329898,
      "loss": 1.6316,
      "step": 100
    },
    {
      "epoch": 0.18900343642611683,
      "grad_norm": 0.9232901930809021,
      "learning_rate": 0.0001625429553264605,
      "loss": 1.671,
      "step": 110
    },
    {
      "epoch": 0.20618556701030927,
      "grad_norm": 0.804553747177124,
      "learning_rate": 0.00015910652920962198,
      "loss": 1.6368,
      "step": 120
    },
    {
      "epoch": 0.22336769759450173,
      "grad_norm": 0.8133351802825928,
      "learning_rate": 0.0001556701030927835,
      "loss": 1.6574,
      "step": 130
    },
    {
      "epoch": 0.24054982817869416,
      "grad_norm": 0.8868284225463867,
      "learning_rate": 0.00015223367697594502,
      "loss": 1.6728,
      "step": 140
    },
    {
      "epoch": 0.25773195876288657,
      "grad_norm": 0.8121822476387024,
      "learning_rate": 0.00014879725085910654,
      "loss": 1.6903,
      "step": 150
    },
    {
      "epoch": 0.27491408934707906,
      "grad_norm": 0.8117738366127014,
      "learning_rate": 0.00014536082474226805,
      "loss": 1.6665,
      "step": 160
    },
    {
      "epoch": 0.2920962199312715,
      "grad_norm": 0.7985167503356934,
      "learning_rate": 0.00014192439862542957,
      "loss": 1.654,
      "step": 170
    },
    {
      "epoch": 0.30927835051546393,
      "grad_norm": 0.7061170339584351,
      "learning_rate": 0.00013848797250859106,
      "loss": 1.6294,
      "step": 180
    },
    {
      "epoch": 0.32646048109965636,
      "grad_norm": 0.7515507340431213,
      "learning_rate": 0.00013505154639175258,
      "loss": 1.6303,
      "step": 190
    },
    {
      "epoch": 0.3436426116838488,
      "grad_norm": 0.8424474000930786,
      "learning_rate": 0.0001316151202749141,
      "loss": 1.5871,
      "step": 200
    },
    {
      "epoch": 0.36082474226804123,
      "grad_norm": 0.8166821599006653,
      "learning_rate": 0.00012817869415807562,
      "loss": 1.6164,
      "step": 210
    },
    {
      "epoch": 0.37800687285223367,
      "grad_norm": 0.7587368488311768,
      "learning_rate": 0.0001247422680412371,
      "loss": 1.6171,
      "step": 220
    },
    {
      "epoch": 0.3951890034364261,
      "grad_norm": 0.8094488382339478,
      "learning_rate": 0.00012130584192439862,
      "loss": 1.5954,
      "step": 230
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 0.8488752245903015,
      "learning_rate": 0.00011786941580756014,
      "loss": 1.6052,
      "step": 240
    },
    {
      "epoch": 0.42955326460481097,
      "grad_norm": 0.8188663721084595,
      "learning_rate": 0.00011443298969072165,
      "loss": 1.6082,
      "step": 250
    },
    {
      "epoch": 0.44673539518900346,
      "grad_norm": 0.8197330236434937,
      "learning_rate": 0.00011099656357388318,
      "loss": 1.6357,
      "step": 260
    },
    {
      "epoch": 0.4639175257731959,
      "grad_norm": 0.7786152958869934,
      "learning_rate": 0.00010756013745704467,
      "loss": 1.5792,
      "step": 270
    },
    {
      "epoch": 0.48109965635738833,
      "grad_norm": 0.7336192727088928,
      "learning_rate": 0.0001041237113402062,
      "loss": 1.6069,
      "step": 280
    },
    {
      "epoch": 0.49828178694158076,
      "grad_norm": 0.8406132459640503,
      "learning_rate": 0.0001006872852233677,
      "loss": 1.5754,
      "step": 290
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 0.9166776537895203,
      "learning_rate": 9.725085910652921e-05,
      "loss": 1.6256,
      "step": 300
    },
    {
      "epoch": 0.5326460481099656,
      "grad_norm": 0.791039764881134,
      "learning_rate": 9.381443298969073e-05,
      "loss": 1.6133,
      "step": 310
    },
    {
      "epoch": 0.5498281786941581,
      "grad_norm": 0.8899490833282471,
      "learning_rate": 9.037800687285224e-05,
      "loss": 1.5126,
      "step": 320
    },
    {
      "epoch": 0.5670103092783505,
      "grad_norm": 0.8032972812652588,
      "learning_rate": 8.694158075601375e-05,
      "loss": 1.625,
      "step": 330
    },
    {
      "epoch": 0.584192439862543,
      "grad_norm": 0.8409477472305298,
      "learning_rate": 8.350515463917527e-05,
      "loss": 1.613,
      "step": 340
    },
    {
      "epoch": 0.6013745704467354,
      "grad_norm": 0.8244235515594482,
      "learning_rate": 8.006872852233678e-05,
      "loss": 1.5424,
      "step": 350
    },
    {
      "epoch": 0.6185567010309279,
      "grad_norm": 0.7819262146949768,
      "learning_rate": 7.663230240549829e-05,
      "loss": 1.6263,
      "step": 360
    },
    {
      "epoch": 0.6357388316151202,
      "grad_norm": 0.8289750218391418,
      "learning_rate": 7.319587628865979e-05,
      "loss": 1.5653,
      "step": 370
    },
    {
      "epoch": 0.6529209621993127,
      "grad_norm": 0.8101164698600769,
      "learning_rate": 6.975945017182131e-05,
      "loss": 1.5718,
      "step": 380
    },
    {
      "epoch": 0.6701030927835051,
      "grad_norm": 0.8069591522216797,
      "learning_rate": 6.632302405498281e-05,
      "loss": 1.5999,
      "step": 390
    },
    {
      "epoch": 0.6872852233676976,
      "grad_norm": 0.794275164604187,
      "learning_rate": 6.288659793814433e-05,
      "loss": 1.554,
      "step": 400
    },
    {
      "epoch": 0.7044673539518901,
      "grad_norm": 0.8387389183044434,
      "learning_rate": 5.945017182130584e-05,
      "loss": 1.5731,
      "step": 410
    },
    {
      "epoch": 0.7216494845360825,
      "grad_norm": 0.8394028544425964,
      "learning_rate": 5.601374570446736e-05,
      "loss": 1.5494,
      "step": 420
    },
    {
      "epoch": 0.738831615120275,
      "grad_norm": 0.7931501865386963,
      "learning_rate": 5.257731958762887e-05,
      "loss": 1.6515,
      "step": 430
    },
    {
      "epoch": 0.7560137457044673,
      "grad_norm": 0.9014414548873901,
      "learning_rate": 4.9140893470790375e-05,
      "loss": 1.5937,
      "step": 440
    },
    {
      "epoch": 0.7731958762886598,
      "grad_norm": 0.8121424317359924,
      "learning_rate": 4.570446735395189e-05,
      "loss": 1.5802,
      "step": 450
    },
    {
      "epoch": 0.7903780068728522,
      "grad_norm": 0.8149255514144897,
      "learning_rate": 4.2268041237113404e-05,
      "loss": 1.5945,
      "step": 460
    },
    {
      "epoch": 0.8075601374570447,
      "grad_norm": 0.8614550232887268,
      "learning_rate": 3.8831615120274915e-05,
      "loss": 1.5559,
      "step": 470
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 0.8929101228713989,
      "learning_rate": 3.539518900343643e-05,
      "loss": 1.5849,
      "step": 480
    },
    {
      "epoch": 0.8419243986254296,
      "grad_norm": 0.7885891199111938,
      "learning_rate": 3.1958762886597937e-05,
      "loss": 1.5656,
      "step": 490
    },
    {
      "epoch": 0.8591065292096219,
      "grad_norm": 0.799950361251831,
      "learning_rate": 2.852233676975945e-05,
      "loss": 1.586,
      "step": 500
    },
    {
      "epoch": 0.8762886597938144,
      "grad_norm": 0.8064143061637878,
      "learning_rate": 2.5085910652920962e-05,
      "loss": 1.5279,
      "step": 510
    },
    {
      "epoch": 0.8934707903780069,
      "grad_norm": 0.8334808349609375,
      "learning_rate": 2.1649484536082476e-05,
      "loss": 1.6626,
      "step": 520
    },
    {
      "epoch": 0.9106529209621993,
      "grad_norm": 0.8860536217689514,
      "learning_rate": 1.8213058419243987e-05,
      "loss": 1.5641,
      "step": 530
    },
    {
      "epoch": 0.9278350515463918,
      "grad_norm": 0.7887476086616516,
      "learning_rate": 1.47766323024055e-05,
      "loss": 1.59,
      "step": 540
    },
    {
      "epoch": 0.9450171821305842,
      "grad_norm": 0.8108449578285217,
      "learning_rate": 1.134020618556701e-05,
      "loss": 1.6165,
      "step": 550
    },
    {
      "epoch": 0.9621993127147767,
      "grad_norm": 0.859167754650116,
      "learning_rate": 7.903780068728522e-06,
      "loss": 1.4809,
      "step": 560
    },
    {
      "epoch": 0.979381443298969,
      "grad_norm": 0.8024299144744873,
      "learning_rate": 4.467353951890034e-06,
      "loss": 1.6339,
      "step": 570
    },
    {
      "epoch": 0.9965635738831615,
      "grad_norm": 0.8705491423606873,
      "learning_rate": 1.0309278350515464e-06,
      "loss": 1.5435,
      "step": 580
    }
  ],
  "logging_steps": 10,
  "max_steps": 582,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.630935701651456e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
