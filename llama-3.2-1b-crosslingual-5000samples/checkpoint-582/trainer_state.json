{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 1000,
  "global_step": 582,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01718213058419244,
      "grad_norm": 0.9049135446548462,
      "learning_rate": 0.00019690721649484537,
      "loss": 2.3438,
      "step": 10
    },
    {
      "epoch": 0.03436426116838488,
      "grad_norm": 0.8603770732879639,
      "learning_rate": 0.0001934707903780069,
      "loss": 1.9449,
      "step": 20
    },
    {
      "epoch": 0.05154639175257732,
      "grad_norm": 0.870430588722229,
      "learning_rate": 0.00019003436426116838,
      "loss": 1.8547,
      "step": 30
    },
    {
      "epoch": 0.06872852233676977,
      "grad_norm": 0.9874497056007385,
      "learning_rate": 0.0001865979381443299,
      "loss": 1.8423,
      "step": 40
    },
    {
      "epoch": 0.0859106529209622,
      "grad_norm": 0.8667659163475037,
      "learning_rate": 0.00018316151202749141,
      "loss": 1.8646,
      "step": 50
    },
    {
      "epoch": 0.10309278350515463,
      "grad_norm": 1.8036521673202515,
      "learning_rate": 0.00017972508591065293,
      "loss": 1.8337,
      "step": 60
    },
    {
      "epoch": 0.12027491408934708,
      "grad_norm": 1.420983076095581,
      "learning_rate": 0.00017628865979381445,
      "loss": 1.7172,
      "step": 70
    },
    {
      "epoch": 0.13745704467353953,
      "grad_norm": 1.0616471767425537,
      "learning_rate": 0.00017285223367697597,
      "loss": 1.7535,
      "step": 80
    },
    {
      "epoch": 0.15463917525773196,
      "grad_norm": 0.8236526250839233,
      "learning_rate": 0.00016941580756013746,
      "loss": 1.7129,
      "step": 90
    },
    {
      "epoch": 0.1718213058419244,
      "grad_norm": 0.785190999507904,
      "learning_rate": 0.00016597938144329898,
      "loss": 1.6821,
      "step": 100
    },
    {
      "epoch": 0.18900343642611683,
      "grad_norm": 0.953269362449646,
      "learning_rate": 0.0001625429553264605,
      "loss": 1.7356,
      "step": 110
    },
    {
      "epoch": 0.20618556701030927,
      "grad_norm": 0.8683677315711975,
      "learning_rate": 0.00015910652920962198,
      "loss": 1.6976,
      "step": 120
    },
    {
      "epoch": 0.22336769759450173,
      "grad_norm": 0.8506358861923218,
      "learning_rate": 0.0001556701030927835,
      "loss": 1.7092,
      "step": 130
    },
    {
      "epoch": 0.24054982817869416,
      "grad_norm": 0.9041861295700073,
      "learning_rate": 0.00015223367697594502,
      "loss": 1.7243,
      "step": 140
    },
    {
      "epoch": 0.25773195876288657,
      "grad_norm": 0.8428396582603455,
      "learning_rate": 0.00014879725085910654,
      "loss": 1.7581,
      "step": 150
    },
    {
      "epoch": 0.27491408934707906,
      "grad_norm": 0.8823819160461426,
      "learning_rate": 0.00014536082474226805,
      "loss": 1.7284,
      "step": 160
    },
    {
      "epoch": 0.2920962199312715,
      "grad_norm": 0.8714691400527954,
      "learning_rate": 0.00014192439862542957,
      "loss": 1.7115,
      "step": 170
    },
    {
      "epoch": 0.30927835051546393,
      "grad_norm": 0.7303537130355835,
      "learning_rate": 0.00013848797250859106,
      "loss": 1.7003,
      "step": 180
    },
    {
      "epoch": 0.32646048109965636,
      "grad_norm": 0.7909435033798218,
      "learning_rate": 0.00013505154639175258,
      "loss": 1.703,
      "step": 190
    },
    {
      "epoch": 0.3436426116838488,
      "grad_norm": 0.8609973788261414,
      "learning_rate": 0.0001316151202749141,
      "loss": 1.6463,
      "step": 200
    },
    {
      "epoch": 0.36082474226804123,
      "grad_norm": 0.8259502649307251,
      "learning_rate": 0.00012817869415807562,
      "loss": 1.6748,
      "step": 210
    },
    {
      "epoch": 0.37800687285223367,
      "grad_norm": 0.7797908782958984,
      "learning_rate": 0.0001247422680412371,
      "loss": 1.68,
      "step": 220
    },
    {
      "epoch": 0.3951890034364261,
      "grad_norm": 0.8218920230865479,
      "learning_rate": 0.00012130584192439862,
      "loss": 1.6612,
      "step": 230
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 0.8645792007446289,
      "learning_rate": 0.00011786941580756014,
      "loss": 1.6728,
      "step": 240
    },
    {
      "epoch": 0.42955326460481097,
      "grad_norm": 0.8380702137947083,
      "learning_rate": 0.00011443298969072165,
      "loss": 1.6711,
      "step": 250
    },
    {
      "epoch": 0.44673539518900346,
      "grad_norm": 0.8206250071525574,
      "learning_rate": 0.00011099656357388318,
      "loss": 1.6963,
      "step": 260
    },
    {
      "epoch": 0.4639175257731959,
      "grad_norm": 0.8253873586654663,
      "learning_rate": 0.00010756013745704467,
      "loss": 1.6371,
      "step": 270
    },
    {
      "epoch": 0.48109965635738833,
      "grad_norm": 0.7635533213615417,
      "learning_rate": 0.0001041237113402062,
      "loss": 1.6674,
      "step": 280
    },
    {
      "epoch": 0.49828178694158076,
      "grad_norm": 0.8570881485939026,
      "learning_rate": 0.0001006872852233677,
      "loss": 1.6332,
      "step": 290
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 0.9580035209655762,
      "learning_rate": 9.725085910652921e-05,
      "loss": 1.6839,
      "step": 300
    },
    {
      "epoch": 0.5326460481099656,
      "grad_norm": 0.8026354908943176,
      "learning_rate": 9.381443298969073e-05,
      "loss": 1.6711,
      "step": 310
    },
    {
      "epoch": 0.5498281786941581,
      "grad_norm": 0.8950977325439453,
      "learning_rate": 9.037800687285224e-05,
      "loss": 1.5666,
      "step": 320
    },
    {
      "epoch": 0.5670103092783505,
      "grad_norm": 0.8157217502593994,
      "learning_rate": 8.694158075601375e-05,
      "loss": 1.6732,
      "step": 330
    },
    {
      "epoch": 0.584192439862543,
      "grad_norm": 0.8463580012321472,
      "learning_rate": 8.350515463917527e-05,
      "loss": 1.6715,
      "step": 340
    },
    {
      "epoch": 0.6013745704467354,
      "grad_norm": 0.8393212556838989,
      "learning_rate": 8.006872852233678e-05,
      "loss": 1.5972,
      "step": 350
    },
    {
      "epoch": 0.6185567010309279,
      "grad_norm": 0.7761330604553223,
      "learning_rate": 7.663230240549829e-05,
      "loss": 1.6713,
      "step": 360
    },
    {
      "epoch": 0.6357388316151202,
      "grad_norm": 0.8574512004852295,
      "learning_rate": 7.319587628865979e-05,
      "loss": 1.6253,
      "step": 370
    },
    {
      "epoch": 0.6529209621993127,
      "grad_norm": 0.8394656181335449,
      "learning_rate": 6.975945017182131e-05,
      "loss": 1.631,
      "step": 380
    },
    {
      "epoch": 0.6701030927835051,
      "grad_norm": 0.796638548374176,
      "learning_rate": 6.632302405498281e-05,
      "loss": 1.6571,
      "step": 390
    },
    {
      "epoch": 0.6872852233676976,
      "grad_norm": 0.7965553402900696,
      "learning_rate": 6.288659793814433e-05,
      "loss": 1.6208,
      "step": 400
    },
    {
      "epoch": 0.7044673539518901,
      "grad_norm": 0.8484724760055542,
      "learning_rate": 5.945017182130584e-05,
      "loss": 1.645,
      "step": 410
    },
    {
      "epoch": 0.7216494845360825,
      "grad_norm": 0.840648889541626,
      "learning_rate": 5.601374570446736e-05,
      "loss": 1.6182,
      "step": 420
    },
    {
      "epoch": 0.738831615120275,
      "grad_norm": 0.8124275207519531,
      "learning_rate": 5.257731958762887e-05,
      "loss": 1.7037,
      "step": 430
    },
    {
      "epoch": 0.7560137457044673,
      "grad_norm": 0.9612374305725098,
      "learning_rate": 4.9140893470790375e-05,
      "loss": 1.6692,
      "step": 440
    },
    {
      "epoch": 0.7731958762886598,
      "grad_norm": 0.8420748710632324,
      "learning_rate": 4.570446735395189e-05,
      "loss": 1.6397,
      "step": 450
    },
    {
      "epoch": 0.7903780068728522,
      "grad_norm": 0.808399498462677,
      "learning_rate": 4.2268041237113404e-05,
      "loss": 1.647,
      "step": 460
    },
    {
      "epoch": 0.8075601374570447,
      "grad_norm": 0.8704817891120911,
      "learning_rate": 3.8831615120274915e-05,
      "loss": 1.6143,
      "step": 470
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 0.932357132434845,
      "learning_rate": 3.539518900343643e-05,
      "loss": 1.6481,
      "step": 480
    },
    {
      "epoch": 0.8419243986254296,
      "grad_norm": 0.7981395125389099,
      "learning_rate": 3.1958762886597937e-05,
      "loss": 1.6349,
      "step": 490
    },
    {
      "epoch": 0.8591065292096219,
      "grad_norm": 0.780531644821167,
      "learning_rate": 2.852233676975945e-05,
      "loss": 1.6342,
      "step": 500
    },
    {
      "epoch": 0.8762886597938144,
      "grad_norm": 0.8319084644317627,
      "learning_rate": 2.5085910652920962e-05,
      "loss": 1.5948,
      "step": 510
    },
    {
      "epoch": 0.8934707903780069,
      "grad_norm": 0.8226568698883057,
      "learning_rate": 2.1649484536082476e-05,
      "loss": 1.7142,
      "step": 520
    },
    {
      "epoch": 0.9106529209621993,
      "grad_norm": 0.9201096892356873,
      "learning_rate": 1.8213058419243987e-05,
      "loss": 1.6266,
      "step": 530
    },
    {
      "epoch": 0.9278350515463918,
      "grad_norm": 0.8079468607902527,
      "learning_rate": 1.47766323024055e-05,
      "loss": 1.6515,
      "step": 540
    },
    {
      "epoch": 0.9450171821305842,
      "grad_norm": 0.8417191505432129,
      "learning_rate": 1.134020618556701e-05,
      "loss": 1.6817,
      "step": 550
    },
    {
      "epoch": 0.9621993127147767,
      "grad_norm": 0.8545327186584473,
      "learning_rate": 7.903780068728522e-06,
      "loss": 1.5368,
      "step": 560
    },
    {
      "epoch": 0.979381443298969,
      "grad_norm": 0.8178255558013916,
      "learning_rate": 4.467353951890034e-06,
      "loss": 1.7067,
      "step": 570
    },
    {
      "epoch": 0.9965635738831615,
      "grad_norm": 0.8635467290878296,
      "learning_rate": 1.0309278350515464e-06,
      "loss": 1.5982,
      "step": 580
    }
  ],
  "logging_steps": 10,
  "max_steps": 582,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.630935701651456e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
